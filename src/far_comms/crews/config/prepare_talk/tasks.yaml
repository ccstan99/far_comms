process_slides_task:
  description: >
    Process and clean slide content for speaker: {speaker}
    
    RAW SLIDES CONTENT:
    {slides_raw}
    
    QR CODES FOUND:
    {qr_codes}
    
    VISUAL ELEMENTS:
    {visual_elements}
    
    SOURCE FILE: {pdf_path}
    
    CODA VALIDATION DATA (source of truth from database):
    - Speaker: "{coda_speaker}"
    - Affiliation: "{coda_affiliation}" 
    - Title: "{coda_title}"
    
    CRITICAL SPEAKER VALIDATION:
    Before processing slides, examine the FIRST SLIDE to extract speaker information and compare against Coda data.
    
    EXTRACT FROM FIRST SLIDE:
    - Speaker name as it appears on the slide
    - Affiliation as it appears on the slide  
    - Title as it appears on the slide
    
    ASSESSMENT GUIDELINES:
    Compare what you found vs the Coda data and assess the degree of difference:
    - "exact_match": Information is identical
    - "minor_differences": Small variations (Robert/Bob, abbreviated titles, etc.)
    - "major_mismatch": Completely different person/content (Adam Gleave vs Adam Kalai)
    
    DO NOT add prefixes or modify the extracted information - just report what you found.
    
    Your processing should:
    - PRESERVE ALL ORIGINAL SLIDE TEXT VERBATIM - do not summarize, paraphrase, or rewrite
    - Clean and structure the provided slide content while keeping exact wording
    - Preserve all technical terminology, formulas, and acronyms exactly as written
    - Maintain the original slide structure and organization
    - SKIP decorative visual elements: logos, profile photos, generic images unless they contain important content
    - Mark important visual elements only: [chart: description] for data charts, [diagram: description] for technical diagrams
    - Include QR codes from the QR CODES FOUND section: insert [QR code to URL] at the relevant slide location so the resource researcher can easily find and use these verified URLs
    - If any slides appear missing from the raw content, note this in processing_notes
    - Extract and catalog MAIN WORK resources only (not comprehensive bibliography):
      * QR code URLs (high priority - intentionally shared by speaker)
      * Primary research paper being presented (usually in title/main slides)
      * Key datasets or codebases that are the focus of the talk
      * SKIP: speaker homepages, institution links, extensive reference lists, related work citations
    - Identify slide titles, main sections, and organizational structure
    
  expected_output: >
    {
      "cleaned_slides": "VERBATIM slide content with exact original text preserved, visual elements marked as [img: alt], [chart: alt], etc. Include banner if major mismatch detected.",
      "slide_structure": {
        "title": "Presentation title from slides (updated if validation passed)",
        "main_sections": ["Section 1", "Section 2", "Section 3"],
        "slide_count": "Number of slides processed"
      },
      "speaker_validation": {
        "slide_speaker": "Exact speaker name as found on first slide",
        "slide_affiliation": "Exact affiliation as found on first slide", 
        "slide_title": "Exact title as found on first slide",
        "validation_result": "exact_match|minor_differences|major_mismatch",
        "validation_notes": "Brief explanation of assessment reasoning"
      },
      "resources_found": [
        {
          "type": "qr_code|url|paper|arxiv|doi|dataset|github|text_reference",
          "title": "Resource title or description", 
          "url": "Direct URL if available (especially for QR codes)",
          "reference": "Original reference as found in slides or QR code",
          "context": "Brief context where it was mentioned",
          "source": "qr_code|slide_text"
        }
      ],
      "technical_terms": ["List of key technical terms and acronyms found"],
      "processing_notes": "Any issues encountered during processing, including speaker validation"
    }
  agent: slide_processor_agent

process_transcript_task:
  description: >
    Clean and format transcript for speaker: {speaker}
    
    RAW TRANSCRIPT (SRT format from AssemblyAI):
    {transcript_raw}
    
    SOURCE: {transcript_source}
    SLIDES CONTEXT (from previous task for technical accuracy):
    Use the slides content from the previous task to ensure name spelling and technical terms are correct.
    
    ---
    TRANSCRIPT STYLE GUIDE:
    {style_transcript}
    ---
    
    CRITICAL REQUIREMENTS - FAILURE TO FOLLOW WILL RESULT IN REJECTION:
    1. WORD COUNT VALIDATION: Your output must contain 95-105% of the original word count
    2. VERBATIM PRESERVATION: Keep EVERY SINGLE WORD from the original transcript
    3. ONLY ALLOWED CHANGES: Fix spelling/terminology using style guide, add paragraph breaks
    4. FORBIDDEN ACTIONS: Do NOT remove, summarize, shorten, or paraphrase ANY content
    5. FORBIDDEN ACTIONS: Do NOT add section headers, titles, or structural elements
    
    Processing steps:
    1. Extract text from SRT format (ignore timestamps - preserved automatically)
    2. Count words in original text and log this number
    3. Apply transcript style guide corrections ONLY for spelling/terminology
    4. Use slide context for technical term accuracy
    5. Organize into paragraphs (50-100 words) at natural topic transitions
    6. Count words in final output - MUST be within 95-105% of original count
    7. If word count drops below 95%, you have failed the task - try again
    
  expected_output: >
    {
      "transcript_formatted": "COMPLETE verbatim transcript text with ALL original words preserved, only corrected technical terms, organized into readable paragraphs, no headers or topic titles - WORD COUNT MUST BE NEARLY IDENTICAL TO ORIGINAL",
      "transcript_stats": {
        "original_word_count": "REQUIRED: Word count from original SRT text",
        "output_word_count": "REQUIRED: Word count in transcript_formatted",
        "word_count_percentage": "REQUIRED: (output/original)*100 - MUST be 95-105%",
        "paragraph_count": "Number of paragraphs created",
        "duration_minutes": "Video duration if available"
      },
      "cleaning_notes": "Details about spelling/terminology corrections made using slide context",
      "processing_status": "success|partial|failed - FAIL if word count below 95%"
    }
  agent: transcript_processor_agent
  context:
    - process_slides_task


final_assembly_task:
  description: >
    Assemble all processed content and prepare final outputs for Coda database update.
    
    Extract the ACTUAL content from previous tasks:
    - Slides: Use "cleaned_slides" content from slide processing task (if not skipped)
    - SRT: Use "transcript_srt" content (with timestamps) from transcript processing task (if not skipped)
    - Transcript: Use "transcript_formatted" content (clean paragraphs) from transcript processing task (if not skipped)
    - Speaker Validation: Apply validated speaker information updates from slide processing
    - Generate processing summary for "Webhook progress" column
    - Set "Webhook status" to "Done"
    
    NOTE: Speaker validation and field updates will be handled by Python post-processing.
    Just include the raw slides content and validation data - do not make decisions about field updates.
    
  expected_output: >
    {
      "coda_updates": {
        "Slides": "Complete slides content with visual elements marked",
        "SRT": "Full SRT transcript with timestamps",
        "Transcript": "Clean formatted transcript paragraphs",
        "Webhook progress": "Processing completed successfully: X slides processed, Y words transcribed",
        "Webhook status": "Done"
      },
      "processing_summary": {
        "slides_processed": "Number of slides",
        "transcript_length": "Word count",
        "speaker_validation": "Validation result and updates applied",
        "total_processing_time": "Processing time"
      }
    }
  agent: slide_processor_agent
  context:
    - process_slides_task
    - process_transcript_task