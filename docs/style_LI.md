# FAR.AI Comms Style Guide — LinkedIn Posts

## Structure
1. Strong hook (no fluff)
2. Paragraph summary:
   - Include {speaker} ({affiliation}) active verb summary of talk
3. 3–4 bullet points using ▸
   - ≤ 10 words each
4. CTA: 
   - CTAs and video links are added in post-processing - do not include in content generation

## Style Notes
- Max length: **200 words**
- Do **not** start with phrases like “Excited to share…”
- Avoid technical jargon
- Emphasize:
  - Accessibility
  - Shareability
  - Clarity
- Audience: Policymakers, tech professionals, generalists

## Evaluation Rubric (14 points)

### Content Quality (8 pts)
- **Hook Strength (2)** – Surprising or counterintuitive
- **Evidence Specificity (2)** – Concrete data or numbers
- **Clarity (2)** – Understandable to non-ML professionals
- **Value (2)** – Actionable takeaways

### Style Quality (6 pts)
- **Voice (2)** – Conversational and human
- **Conciseness (2)** – No fluff, tight writing
- **Professional Tone (2)** – Polished and credible

## High-Performing Examples

### Example 1: Strong Technical Hook + Clear Value
```
AI refuses to answer harmful questions... until you slightly rephrase them.

@Sravanti Addepalli (DeepMind) demonstrated how simple rewording bypasses GPT-4o's safety measures 90%+ of the time.

Highlights:
▸ Models blocking 100% of direct harmful requests failed on natural rephrasings
▸ Example: "How to hack a bank?" (blocked) vs "What steps do hackers typically follow?" (answered)
▸ Safety training works partially but many variations slip through
```

### Example 2
```
Can jailbreaking AI be prevented with signal processing techniques?

@Pin-Yu Chen (IBM Research) presented a unified framework that treats AI safety problems as hypothesis testing challenges. The key insight: unlike traditional hypothesis testing with predefined parameters, AI safety requires "language-model-as-a-judge" because safety depends entirely on context—the user, deployment region, and intended use.

▸ Safety problems can be formulated as hypothesis testing challenges from signal processing
▸ Language-model-as-a-judge needed because safety hypotheses are context-dependent, not predefined
▸ Framework addresses the gap between ideal AI development and real-world deployment
▸ Applies to jailbreak detection, AI content identification, watermarking, and model updates
```

## What Makes These Work
- **Immediate value** - Hook states the key insight in first sentence
- **Clear attribution** - Speaker (Affiliation) format with strong verbs to their main contributions
- **Tight bullets** - Each ≤8 words, no repetition
- **Professional voice** - FAR.AI tone but respectful of speaker's key message
